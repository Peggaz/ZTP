Wady i zalety algorytmów genetycznych
Zalety:
Metoda jest uniwersalna. Aby tego samego programu użyć w innym problemie, przeważnie wystarczy zmienić funkcję celu.
Algorytmy ewolucyjne potrafią poradzić sobie również tam, gdzie optymalizowana funkcja jest zaszumiona, zmienia się w czasie, ma wiele ekstremów lokalnych.
Aby znaleźć rozwiązanie, nie musimy prawie nic wiedzieć o optymalizowanej funkcji (“czarna skrzynka”). Funkcji celu może nawet w ogóle nie być: możemy wykorzystywać algorytmy genetyczne nawet wtedy, gdy jedyną rzeczą, jaką potrafimy powiedzieć o punktach przestrzeni stanów jest to, który z dwóch punktów jest lepszy (selekcja turniejowa).
Metoda jest stosunkowo szybka: znalezienie rozwiązania często jest możliwe po przejrzeniu zaskakująco niewielkiej części przestrzeni stanów.
Ponieważ algorytm genetyczny jest algorytmem randomizowanym, możemy powtarzać obliczenia wielokrotnie w nadziei otrzymania lepszych wyników.
Wady:
Metoda jest uniwersalna, więc nie tak skuteczna, jak bywają algorytmy specjalizowane (rada: stosować algorytmy hybrydowe).
Metoda jest wolniejsza od prostych heurystyk (np. metody zachłannej), choć zwykle skuteczniejsza.
Sukces jest możliwy wyłącznie przy prawidłowym zakodowaniu problemu i odpowiednim dobraniu funkcji celu. Niestety, nie ma jednoznacznej teorii mówiącej, jak to robić. Jest to często - podobnie jak dobór parametrów mutacji i krzyżowania - sprawa wyczucia i doświadczenia programisty (rada: nabierać doświadczenia!).
Ponieważ algorytm genetyczny jest algorytmem randomizowanym, nigdy nie mamy pewności, że znaleźliśmy rozwiązanie optymalne (rada: zadowolić się rozwiązaniem przybliżonym).
Strategie ewolucyjne:
Inna - obok algorytmów genetycznych - popularna metoda ewolucyjna. Główny obszar zastosowań to optymalizacja funkcji rzeczywistych wielowymiarowych. W przypadku algorytmów genetycznych zakodowanie parametrów liczbowych wymaga ustalenia liczby bitów, co ogranicza nam dokładność obliczeń. W przypadku strategii ewolucyjnych kod genetyczny składa się po prostu z liczb zmiennoprzecinkowych (o precyzji limitowanej tylko przez używany język programowania), co znacznie ułatwia kodowanie problemu i poprawia dokładność końcowego rozwiązania.
Przykład: znaleźć maksimum funkcji f : Rn -> R na danym przedziale [a1 , b1] x ... x [an , bn].
Przez x = (x1, ... xn) oznaczmy przykładowe rozwiązanie (punkt z przestrzeni stanów, przy czym xi należy do przedziału [ai , bi]). Każdemu wektorowi x przyporządkujmy ponadto pomocniczy wektor wartości rzeczywistych dodatnich: s=(s1, ... sn). Para (x,s) będzie stanowiła kod genetyczny osobnika.
Strategie ewolucyjne:
Schemat działania strategii ewolucyjnych jest zbliżony do schematu algorytmu genetycznego - też składa się z etapów wykorzystania operatorów genetycznych, liczenia wartości funkcji celu i przeprowadzania selekcji. Główna różnica polega na innym działaniu i znaczeniu operatora mutacji, a także tradycyjnie innym schemacie selekcji:
1) Tworzymy losową populację złożoną z N osobników postaci (x,s).
2) Dopisujemy do niej M osobników potomnych, tworzonych na podstawie losowo wybranych osobników z poprzedniego pokolenia za pomocą mutacji i krzyżowania.
3) Dla każdego osobnika w populacji pośredniej liczymy wartość optymalizowanej funkcji.
4) Spośród N+M osobników wybieramy N najlepszych względem f(x). Te osobniki przeżyją i utworzą następne pokolenie.
5) Powtarzamy od punktu 2. z aktualną populacją N-osobnikową.
Selekcja w alg. strategii ewolucyjnych:
Mutacji podlegają zwykle wszystkie osobniki dodawane do populacji pośredniej. Mutacja polega na zmianie parametrów (x,s) zgodnie ze wzorami:
Mutacja w alg. strategii ewolucyjnych
gdzie N(0,a) oznacza liczbę losową wygenerowaną zgodnie z rozkładem normalnym o wart. oczekiwanej 0 i odchyleniu standardowym a.
Krzyżowaniu podlega część (np. 25%) osobników dodawanych do populacji pośredniej. Osobnik potomny składany jest z genów dwóch losowo wybranych osobników rodzicielskich. Każdy gen (tzn. każdą składową xi) wybieramy z losowego z dwójki rodziców, przy czym wartości te są dziedziczone zawsze razem z odpowiadającymi im wartościami pomocniczymi si.
Powyższy schemat wskazuje na znaczącą rolę mutacji (w porównaniu z klasycznym algorytmem genetycznym, gdzie mutacje są rzadkie, a za kierunek ewolucji bardziej odpowiada krzyżowanie). Przeszukiwanie przestrzeni stanów polega tu na losowym (gaussowskim) przechodzeniu z danego punktu przestrzeni do pewnego innego, zwykle niezbyt odległego. Wielkość kroków w każdym wymiarze regulują parametry si - im większe, tym (średnio) dalej osobnik się przeniesie wskutek mutacji.
Różnica w sposobie kodowania osobników wskazuje też na zakres zastosowania algorytmów genetycznych i strategii ewolucyjnych. Jeśli zadanie jest typu kombinatorycznego (np. "Znaleźć podzbiór..." albo "Wyznaczyć optymalną kolejność...") lub jest określone na liczbach całkowitych, lepiej się sprawdza algorytm genetyczny i binarne kodowanie rozwiązań. Natomiast zadania, w których wynik jest wartością zmiennoprzecinkową (np. wielowymiarową, jak w zadaniu: "Wyznaczyć optymalne wymiary turbiny samolotu..."), lepiej sprawdzają się strategie ewolucyjne.
Terminem samoadaptacja określa się sytuację, w której ewolucji podlegają nie tylko parametry rozwiązania problemu, ale też parametry samego procesu ewolucji. Potencjalnie daje to możliwość sprawniejszej pracy metod ewolucyjnych: skoro nie zawsze łatwo jest dobrać właściwe parametry pracy algorytmu, to rozsądnym się wydaje poszukiwanie ich metodami ewolucyjnymi. Pozostaje pytanie, jak oceniać wybór konkretnych wartości parametrów (jaka ma być funkcja celu)? Na szczęście okazuje się, że nie jest potrzebna osobna funkcja celu, co zobaczymy na przykładzie strategii ewolucyjnych.
Typowy przebieg optymalizacji za pomocą metody strategii ewolucyjnych jest następujący: początkowo osobniki próbkują różne miejsca przestrzeni stanów, utrzymując jednocześnie stosunkowo wysoką wartość parametrów s (dzięki czemu mutacje sprzyjają szerokiej eksploracji przestrzeni). Kiedy jednak osobniki znajdą się w pobliżu maksimum (globalnego lub izolowanego lokalnego), wówczas ich parametry s gwałtownie maleją, niekiedy o wiele rzędów wielkości. Takie zachowanie parametrów powoduje, że mutacje stają się coraz subtelniejsze i coraz dokładniej przybliżają wartość maksimum. Okazuje się, że za takie "inteligentne" zachowanie się parametrów s odpowiada właśnie zjawisko samoadaptacji.
Aby ewolucja promowała pewne cechy, nie muszą być one bezpośrednio oceniane przez algorytm ewolucyjny. Zauważmy, że funkcja celu zależy wyłącznie od wektora wartości x, czyli parametrów rozwiązania. Z drugiej strony, określone wartości pomocniczych parametrów s też mogą być promowane, o ile prowadzą w kolejnych pokoleniach do znalezienia lepszych wartości ocenianych bezpośrednio parametrów x. Takie zjawisko obserwujemy w przypadku zbliżania się do lokalnego maksimum funkcji celu: niewielkie wartości s są ewolucyjnie korzystne, gdyż mutacja oparta o parametr s nie spowoduje zbyt odległej "ucieczki" od tego maksimum (a może spowodować jeszcze dokadniejsze zbliżenie się do maksimum). Z drugiej strony, jeśli eksplorujemy obszary przestrzeni stanów odległe od maksimum, wówczas odległe "skoki" (mutacje przy wysokim parametrze s) często bywają korzystne.
Poniższe ilustracje są przykładem opisanych wyżej zjawisk. Załóżmy dla uproszczenia, że każdy z osobników ma dwóch potomków i że etap selekcji przeżyje tylko najlepszy osobnik (pogrubione kółko). Osobniki zielone mają wysoką wartość parametru s, osobniki czerwone - niską. Widzimy, że jeśli (wspólny) punkt startowy leży niedaleko maksimum lokalnego, wówczas przeżyje ten osobnik, który miał mniejszą wartość s. Natomiast na "zboczu" funkcji celu, tzn. z dala od maksimów lokalnych, presja selekcyjna wypromuje wysokie wartości s.